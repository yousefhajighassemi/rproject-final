{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\"></center><br/>\n",
    "\n",
    "# Assignment: Notebook for Peer Assignment\n",
    "\n",
    "Estimated time needed: 60 minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Scenario\n",
    "\n",
    "Congratulations! You have just been hired by a US Weather forecast firm as a data scientist.\n",
    "\n",
    "The company is considering the weather condition to help predict the possibility of precipitations, which involves using various local climatological variables, including temperature, wind speed, humidity, dew point, and pressure. The data you will be handling was collected by a NOAA weather station located at the John F. Kennedy International Airport in Queens, New York.\n",
    "\n",
    "Your task is to provide a high level analysis of weather data in JFK Airport. Your stakeholders want to understand the current and historical record of precipitations based on different variables. For now they are mainly interested in a macro-view of JFK Airport Weather, and how it relates to the possibility to rain because it will affect flight delays and etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This project relates to the NOAA Weather Dataset - JFK Airport (New York). The original dataset contains 114,546 hourly observations of 12 local climatological variables (such as temperature and wind speed) collected at JFK airport. This dataset can be obtained for free from the IBM Developer [Data Asset Exchange](https://developer.ibm.com/exchanges/data/all/jfk-weather-data/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0151ENSkillsNetwork926-2022-01-01). \n",
    "\n",
    "For this project, you will be using a subset dataset, which contains 5727 rows (about 5% or original rows) and 9 columns. The end goal will be to predict the precipitation using some of the available features. In this project, you will practice reading data files, preprocessing data, creating models, improving models and evaluating them to ultimately choose the best model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Table of Contents:\n",
    "\n",
    "Using this R notebook you will complete **10 tasks**:\n",
    "* [0. Import Modules](#cell0)\n",
    "* [1. Download and Unzip NOAA Weather Dataset](#cell1)\n",
    "* [2. Read Dataset into Project](#cell2)\n",
    "* [3. Select Subset of Columns](#cell3)\n",
    "* [4. Clean Up Columns](#cell4)\n",
    "* [5. Convert Columns to Numerical Types](#cell5)\n",
    "* [6. Rename Columns](#cell6)\n",
    "* [7. Exploratory Data Analysis](#cell7)\n",
    "* [8. Linear Regression](#cell8)\n",
    "* [9. Improve the Model](#cell9)\n",
    "* [10. Find Best Model](#cell10)\n",
    "\n",
    "\n",
    "<a id=\"cell0\"></a>\n",
    "## 0. Import required modules\n",
    "\n",
    "Below, install \"tidymodels\", additionally \"rlang\" should be updated in order to properly run \"tidymodels\". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install tidymodels if you haven't done so\n",
    "install.packages(\"rlang\")\n",
    "install.packages(\"tidymodels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: After installing the packages, restart the kernel. Without installing the packages again, load them. Tidyverse and Tidymodels will be the two main packages you will use.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library for modeling\n",
    "library(tidymodels)\n",
    "\n",
    "# Load tidyverse\n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Understand the Dataset\n",
    "\n",
    "The original NOAA JFK dataset contains 114,546 hourly observations of various local climatological variables (including temperature, wind speed, humidity, dew point, and pressure). \n",
    "\n",
    "In this project you will use a sample dataset, which is around 293 KB. [Link to the sample dataset](https://dax-cdn.cdn.appdomain.cloud/dax-noaa-weather-data-jfk-airport/1.1.4/noaa-weather-sample-data.tar.gz).\n",
    "\n",
    "The sample contains 5727 rows (about 5% or original rows) and 9 columns, which are:\n",
    "- DATE\n",
    "- HOURLYDewPointTempF\n",
    "- HOURLYRelativeHumidity\n",
    "- HOURLYDRYBULBTEMPF\n",
    "- HOURLYWETBULBTEMPF\n",
    "- HOURLYPrecip\n",
    "- HOURLYWindSpeed\n",
    "- HOURLYSeaLevelPressure\n",
    "- HOURLYStationPressure\n",
    "\n",
    "The original dataset is much bigger. Feel free to explore the original dataset. [Link to the original dataset.](https://dax-cdn.cdn.appdomain.cloud/dax-noaa-weather-data-jfk-airport/1.1.4/noaa_weather.html) \n",
    "\n",
    "For more information about the dataset, checkout the [preview](https://dax-cdn.cdn.appdomain.cloud/dax-noaa-weather-data-jfk-airport/1.1.4/data-preview/index.html?_ga=2.176781478.281508226.1616293518-1509963377.1616117067&cm_mc_uid=90945889198916153255549&cm_mc_sid_50200000=64650651616293516933) of NOAA Weather - JFK Airport.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell1\"></a>\n",
    "\n",
    "## 1. Download NOAA Weather Dataset\n",
    "\n",
    "Use the `download.file()` function to download the sample dataset from the URL below.\n",
    "\n",
    "URL = 'https://dax-cdn.cdn.appdomain.cloud/dax-noaa-weather-data-jfk-airport/1.1.4/noaa-weather-sample-data.tar.gz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'download' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67/795149044.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdownload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://dax-cdn.cdn.appdomain.cloud/dax-noaa-weather-data-jfk-airport/1.1.4/noaa-weather-sample-data.tar.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"noaa-weather-sample.tar.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'download' is not defined"
     ]
    }
   ],
   "source": [
    "download.file(url = \"https://dax-cdn.cdn.appdomain.cloud/dax-noaa-weather-data-jfk-airport/1.1.4/noaa-weather-sample-data.tar.gz\", destfile = \"noaa-weather-sample.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untar the zipped file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'untar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67/1276226495.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muntar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"noaa-weather-sample.tar.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'untar' is not defined"
     ]
    }
   ],
   "source": [
    "untar(\"noaa-weather-sample.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell2\"></a>\n",
    "## 2. Extract and Read into Project\n",
    "We start by reading in the raw dataset. You should specify the file name as \"noaa-weather-sample-data/jfk_weather_sample.csv\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'noaa_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67/1583579846.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnoaa_data\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"jfk_weather_sample.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'noaa_data' is not defined"
     ]
    }
   ],
   "source": [
    "noaa_data <- read_csv(\"jfk_weather_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, display the first few rows of the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'head' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67/2346919335.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoaa_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'head' is not defined"
     ]
    }
   ],
   "source": [
    "head(noaa_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, take a `glimpse` of the dataset to see the different column data types and make sure it is the correct subset dataset with about 5700 rows and 9 columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glimpse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67/4030105403.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglimpse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoaa_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'glimpse' is not defined"
     ]
    }
   ],
   "source": [
    "glimpse(noaa_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell3\"></a>\n",
    "## 3. Select Subset of Columns\n",
    "\n",
    "The end goal of this project will be to predict `HOURLYprecip` (precipitation) using a few other variables. Before you can do this, you first need to preprocess the dataset. Section 3 to section 6 focuses on preprocessing.\n",
    "\n",
    "The first step in preprocessing is to select a subset of data columns and inspect the column types.\n",
    "\n",
    "The key columns that we will explore in this project are:\n",
    "- HOURLYRelativeHumidity\n",
    "- HOURLYDRYBULBTEMPF\n",
    "- HOURLYPrecip\n",
    "- HOURLYWindSpeed\n",
    "- HOURLYStationPressure\n",
    "\n",
    "Data Glossary:\n",
    "- 'HOURLYRelativeHumidity' is the relative humidity given to the nearest whole percentage.\n",
    "- 'HOURLYDRYBULBTEMPF' is the dry-bulb temperature and is commonly used as the standard air temperature reported. It is given here in whole degrees Fahrenheit.\n",
    "- 'HOURLYPrecip' is the amount of precipitation in inches to hundredths over the past hour. For certain automated stations, precipitation will be reported at sub-hourly intervals (e.g. every 15 or 20 minutes) as an accumulated amount of all precipitation within the preceding hour. A “T” indicates a trace amount of precipitation.\n",
    "- 'HOURLYWindSpeed' is the speed of the wind at the time of observation given in miles per hour (mph).\n",
    "- 'HOURLYStationPressure' is the atmospheric pressure observed at the station during the time of observation. Given in inches of Mercury (in Hg).\n",
    "\n",
    "`Select` those five columns and store the modified dataframe as a new variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'noaa_subset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67/2606335088.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m noaa_subset <- select(noaa_data, 'HOURLYRelativeHumidity', 'HOURLYDRYBULBTEMPF' , 'HOURLYPrecip' , \n\u001b[0m\u001b[1;32m      2\u001b[0m        'HOURLYWindSpeed' , 'HOURLYStationPressure')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'noaa_subset' is not defined"
     ]
    }
   ],
   "source": [
    "noaa_subset <- select(noaa_data, 'HOURLYRelativeHumidity', 'HOURLYDRYBULBTEMPF' , 'HOURLYPrecip' , \n",
    "       'HOURLYWindSpeed' , 'HOURLYStationPressure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first 10 rows of this new dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'head' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67/3310441276.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoaa_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'head' is not defined"
     ]
    }
   ],
   "source": [
    "head(noaa_subset, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell4\"></a>\n",
    "## 4. Clean Up Columns\n",
    "\n",
    "From the dataframe preview above, we can see that the column `HOURLYPrecip` - which is the hourly measure of precipitation levels - contains both `NA` and `T` values. `T` specifies *trace amounts of precipitation* (meaning essentially no precipitation), while `NA` means *not available*, and is used to denote missing values. Additionally, some values also have \"s\" at the end of them, indicating that the precipitation was snow. \n",
    "\n",
    "Inspect the unique values present in the column `HOURLYPrecip` (with `unique(dataframe$column)`) to see these values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2254242018.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_67/2254242018.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    unique(noaa_subset$HOURLYPrecip)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "unique(noaa_subset$HOURLYPrecip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having characters in values (like the \"T\" and \"s\" that you see in the unique values) will cause problems when you create a model because values for precipitation should be numerical. So you need to fix these values that have characters. \n",
    "\n",
    "Now, for the column `HOURLYPrecip`:\n",
    "1. Replace all the `T` values with \"0.0\" and \n",
    "2. Remove \"s\" from values like \"0.02s\". In R, you can use the method `str_remove(column, pattern = \"s$\")` to remove the character \"s\" from the end of values. The \"$\" tells R to match to the end of values. The `pattern` is a regex pattern. Look at [here](https://www.rdocumentation.org/packages/stringi/versions/1.5.3/topics/about_search_regex?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0151ENSkillsNetwork926-2022-01-01) for more information about regex and matching to strings in R.\n",
    "\n",
    "Remember that you can use `tidyverse`'s  `mutate()` to update columns.\n",
    "\n",
    "You can check your work by checking if unique values of `HOURLYPrecip` still contain any `T` or `s`. Store the modified dataframe as a new variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1719062920.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_67/1719062920.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    noaa_subsetwrangled <-  noaa_subset %>% mutate(HOURLYPrecip = ifelse(HOURLYPrecip == \"T\", \"0.0\", HOURLYPrecip)) # replacing the \"T\" in the column HOURLYPrecip with \"0.0\"\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "noaa_subsetwrangled <-  noaa_subset %>% mutate(HOURLYPrecip = ifelse(HOURLYPrecip == \"T\", \"0.0\", HOURLYPrecip)) # replacing the \"T\" in the column HOURLYPrecip with \"0.0\"\n",
    "unique(noaa_subsetwrangled$HOURLYPrecip) # checking if the \"T\"s are gone\n",
    "\n",
    "noaa_subsetwrangled <- noaa_subsetwrangled %>% mutate(HOURLYPrecip = str_remove(HOURLYPrecip, pattern = \"s$\")) # removing the \"s\" in the end of the numbers\n",
    "unique(noaa_subsetwrangled$HOURLYPrecip) # checking if the \"s\" are gone too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell5\"></a>\n",
    "## 5. Convert Columns to Numerical Types\n",
    "Now that you have removed the characters in the `HOURLYPrecip` column, you can safely covert the column to a numeric type.\n",
    "\n",
    "First, check the types of the columns. You will notice that all are `dbl` (double or numeric) except for `HOURLYPrecip`, which is `chr` (character or string). Use the `glimpse` function from Tidyverse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glimpse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67/3530188512.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglimpse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoaa_subsetwrangled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'glimpse' is not defined"
     ]
    }
   ],
   "source": [
    "glimpse(noaa_subsetwrangled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `HOURLYPrecip` to the `numeric` type and store the cleaned dataframe as a new variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2229390513.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_67/2229390513.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    noaa_subsetwrangledn <- noaa_subsetwrangled %>% mutate(HOURLYPrecip = as.numeric(HOURLYPrecip))\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "noaa_subsetwrangledn <- noaa_subsetwrangled %>% mutate(HOURLYPrecip = as.numeric(HOURLYPrecip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that all fields have numerical data type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glimpse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67/1273086144.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglimpse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoaa_subsetwrangledn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'glimpse' is not defined"
     ]
    }
   ],
   "source": [
    "glimpse(noaa_subsetwrangledn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell6\"></a>\n",
    "## 6. Rename Columns\n",
    "Let's rename the following columns as:\n",
    "- 'HOURLYRelativeHumidity' to 'relative_humidity'\n",
    "- 'HOURLYDRYBULBTEMPF' to 'dry_bulb_temp_f'\n",
    "- 'HOURLYPrecip' to 'precip'\n",
    "- 'HOURLYWindSpeed' to 'wind_speed'\n",
    "- 'HOURLYStationPressure' to 'station_pressure'\n",
    "\n",
    "You can use `dplyr::rename()`. Then, store the final dataframe as a new variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'noaa_subsetwranglednn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67/3923814716.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnoaa_subsetwranglednn\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mnoaa_subsetwrangledn\u001b[0m \u001b[0;31m# creating a new data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m colnames(noaa_subsetwranglednn) <- c(\"relative_humidity\", \"dry_bulb_temp_f\", \n\u001b[1;32m      4\u001b[0m                                      \"precip\", \"wind_speed\", \"station_pressure\") # changing the column names to what was requested\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'noaa_subsetwranglednn' is not defined"
     ]
    }
   ],
   "source": [
    "noaa_subsetwranglednn <- noaa_subsetwrangledn # creating a new data frame\n",
    "\n",
    "colnames(noaa_subsetwranglednn) <- c(\"relative_humidity\", \"dry_bulb_temp_f\", \n",
    "                                     \"precip\", \"wind_speed\", \"station_pressure\") # changing the column names to what was requested\n",
    "\n",
    "glimpse(noaa_subsetwranglednn)  # checking whether the changes took place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell7\"></a>\n",
    "## 7. Exploratory Data Analysis\n",
    "Now that you have finished preprocessing the dataset, you can can start exploring the columns more.\n",
    "\n",
    "First, split the data into a training and testing set. Splitting a dataset is done randomly, so to have reproducible results set the seed = 1234. Also, use 80% of the data for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4138142139.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_67/4138142139.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    noaa_split <- noaa_subsetwranglednn %>% initial_split(prop = 0.8) # splitting the dataset\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "set.seed(1234)\n",
    "\n",
    "noaa_split <- noaa_subsetwranglednn %>% initial_split(prop = 0.8) # splitting the dataset\n",
    "noaa_training <- training(noaa_split) # creating the training subset\n",
    "noaa_testing <- testing(noaa_split) # creating the testing subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, looking at just the **training set**, plot histograms or box plots of the variables (`relative_humidity`, `dry_bulb_temp_f`, `precip`, `wind_speed`,  `station_pressure`) for an intial look of their distributions using `tidyverse`'s `ggplot`. Leave the testing set as is because it is good practice to not see the testing set until evaluating the final model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2384042941.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_67/2384042941.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    ggplot(noaa_training, mapping = aes(x = noaa_training$relative_humidity)) +\u001b[0m\n\u001b[0m                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"ggplot2\") # installing the ggplot package\n",
    "library(ggplot2)\n",
    "\n",
    "ggplot(noaa_training, mapping = aes(x = noaa_training$relative_humidity)) +\n",
    "  geom_histogram(color = \"black\", fill = \"red\")\n",
    "\n",
    "ggplot(noaa_training, mapping = aes(x = noaa_training$dry_bulb_temp_f)) +\n",
    "  geom_histogram(color = \"black\", fill = \"red\")\n",
    "\n",
    "ggplot(noaa_training, mapping = aes(x = noaa_training$precip)) +\n",
    "  geom_histogram(color = \"black\", fill = \"red\")\n",
    "\n",
    "ggplot(noaa_training, mapping = aes(x = noaa_training$wind_speed)) +\n",
    "  geom_histogram(color = \"black\", fill = \"red\")\n",
    "\n",
    "ggplot(noaa_training, mapping = aes(x = noaa_training$station_pressure)) +\n",
    "  geom_histogram(color = \"black\", fill = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell8\"></a>\n",
    "## 8. Linear Regression \n",
    "After exploring the dataset more, you are now ready to start creating models to predict the precipitation (`precip`).\n",
    "\n",
    "Create simple linear regression models where `precip` is the response variable and each of `relative_humidity`, `dry_bulb_temp_f`,`wind_speed` or `station_pressure` will be a predictor variable, e.g. `precip ~ relative_humidity`, `precip ~ dry_bulb_temp_f`, etc. for a total of four simple models. \n",
    "Additionally, visualize each simple model with a scatter plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (404497712.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_67/404497712.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    model1 <- lm(noaa_training$precip~relative_humidity)\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "attach(noaa_training) # to create separate elements for each column (variable)\n",
    "\n",
    "model1 <- lm(noaa_training$precip~relative_humidity)\n",
    "summary(model1)\n",
    "  \n",
    "ggplot(noaa_training, mapping = aes(x = relative_humidity, y = noaa_training$precip)) +\n",
    "  geom_point() +\n",
    "  geom_smooth(method = \"lm\", formula = y~x, \n",
    "              col = \"green\", se = FALSE, na.rm = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3526673494.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_67/3526673494.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    model2 <- lm(noaa_training$precip~dry_bulb_temp_f)\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model2 <- lm(noaa_training$precip~dry_bulb_temp_f)\n",
    "summary(model2)\n",
    "\n",
    "ggplot(noaa_training, mapping = aes(x = dry_bulb_temp_f, y = noaa_training$precip)) +\n",
    "  geom_point() +\n",
    "  geom_smooth(method = \"lm\", formula = y~x, \n",
    "              col = \"blue\", se = FALSE, na.rm = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (960578477.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_67/960578477.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    model3 <- lm(noaa_training$precip~wind_speed)\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model3 <- lm(noaa_training$precip~wind_speed)\n",
    "summary(model3)\n",
    "\n",
    "ggplot(noaa_training, mapping = aes(x = wind_speed, y = noaa_training$precip)) +\n",
    "  geom_point() +\n",
    "  geom_smooth(method = \"lm\", formula = y~x, \n",
    "              col = \"red\", se = FALSE, na.rm = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1504376728.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_67/1504376728.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    model4 <- lm(noaa_training$precip~station_pressure)\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model4 <- lm(noaa_training$precip~station_pressure)\n",
    "summary(model4)\n",
    "\n",
    "ggplot(noaa_training, mapping = aes(x = station_pressure, y = noaa_training$precip)) +\n",
    "  geom_point() +\n",
    "  geom_smooth(method = \"lm\", formula = y~x, \n",
    "              col = \"purple\", se = FALSE, na.rm = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell9\"></a>\n",
    "## 9. Improve the Model\n",
    "Now, try improving the simple models you created in the previous section. \n",
    "\n",
    "Create at least two more models, each model should use at least one of the different techniques:\n",
    "1. Add more features/predictors\n",
    "2. Add regularization (L1, L2 or a mix)\n",
    "3. Add a polynomial component\n",
    "\n",
    "Also, for each of the models you create, check the model performance using the **training set** and a metric like MSE, RMSE, or R-squared.\n",
    "\n",
    "Consider using `tidymodels` if you choose to add regularization and tune lambda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (76833021.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_67/76833021.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    map(noaa_training, ~sum(is.na(.))) # how many missing values do we have in each column of the dataset\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## Improved model 1 (using all 4 explanatory variables, in a ridge model, also pbtaining lambda by grid search):\n",
    "\n",
    "# for computing such a model, the NA (missing values should be deleted from the training dataset)\n",
    "map(noaa_training, ~sum(is.na(.))) # how many missing values do we have in each column of the dataset\n",
    "noaa_training1 <- noaa_training %>% drop_na(c(relative_humidity, dry_bulb_temp_f, wind_speed, station_pressure, precip))\n",
    "map(noaa_training1, ~sum(is.na(.))) # we have now deleted ALL the missing values (NAs)\n",
    "\n",
    "dim(noaa_training)\n",
    "dim(noaa_training1) # as a result of dropping the NAs, we will inevitably lose about 1000 observations\n",
    "\n",
    "improved_recipe <- recipe(precip ~ relative_humidity + \n",
    "                            dry_bulb_temp_f + wind_speed + station_pressure, \n",
    "                          data = noaa_training1)\n",
    "\n",
    "improved_ridge <- linear_reg(penalty = tune(), mixture = 0) %>%\n",
    "  set_engine(\"glmnet\")\n",
    "\n",
    "noaa_cvfolds <- vfold_cv(noaa_training1)\n",
    "\n",
    "lambda_grid <- grid_regular(levels = 250,\n",
    "                            penalty(range = c(-3,0.3)))\n",
    "\n",
    "ridge_wf <- workflow() %>%\n",
    "  add_recipe(improved_recipe)\n",
    "\n",
    "ridge_grid <- tune_grid(\n",
    "  \n",
    "  ridge_wf %>% add_model(improved_ridge),\n",
    "  resamples = noaa_cvfolds,\n",
    "  grid = lambda_grid\n",
    ") \n",
    "\n",
    "show_best(ridge_grid, metric = \"rmse\") # The best penalty (with the lowest RMSE) is found as 0.00749\n",
    "\n",
    "# This lambda now will be used in the ridge regression:\n",
    "improved_recipe <- recipe(precip ~ relative_humidity + \n",
    "                            dry_bulb_temp_f + wind_speed + station_pressure, \n",
    "                          data = noaa_training1)\n",
    "\n",
    "improved_ridge <- linear_reg(penalty = 0.00749, mixture = 0) %>%\n",
    "  set_engine(\"glmnet\")\n",
    "\n",
    "ridge_workflow <- workflow() %>%\n",
    "  add_recipe(improved_recipe)\n",
    "\n",
    "ridge_fit <- ridge_workflow %>%\n",
    "  add_model(improved_ridge) %>%\n",
    "  fit(data = noaa_training1) \n",
    "\n",
    "ridge_fit %>% \n",
    "  pull_workflow_fit() %>%\n",
    "  tidy() # the coefficients of the ridge regression\n",
    "\n",
    "# I think in this case, the RMSE is going to be the same as the mean of RMSE\n",
    "# as computed in the Grid Search step.\n",
    "# That gave us the optimum lambda. So I would say RMSE is equal to 0.0382.\n",
    "ridge_rmse_training <- 0.0382\n",
    "\n",
    "\n",
    "## IMPROVED MODEL 2 (A simple polynomial model by using the second degree polynomial of explanatory variables of relative humidity and station pressure):\n",
    "\n",
    "relative_humidity_sq <- relative_humidity^2 \n",
    "station_pressure_sq <- station_pressure^2\n",
    "improved_polynomial <- lm(noaa_training$precip ~ relative_humidity + relative_humidity_sq + station_pressure + station_pressure_sq)\n",
    "summary(improved_polynomial) # the results\n",
    "\n",
    "poly_rmse_training <- improved_polynomial$residuals^2 %>% mean() %>% sqrt() # the RMSE of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cell10\"></a>\n",
    "## 10. Find Best Model\n",
    "Compare the regression metrics of each model from section 9 to find the best model overall. To do this, \n",
    "\n",
    "1. Evaluate the models on the **testing set** using at least one metric (like MSE, RMSE or R-squared).\n",
    "2. After calculating the metrics on the testing set for each model, print them out in as a table to easily compare. You can use something like:\n",
    "```\n",
    "model_names <- c(\"model_1\", \"model_2\", \"model_3\")\n",
    "train_error <- c(\"model_1_value\", \"model_2_value\", \"model_3_value\")\n",
    "test_error <- c(\"model_1_value\", \"model_2_value\", \"model_3_value\")\n",
    "comparison_df <- data.frame(model_names, train_error, test_error)\n",
    "```\n",
    "3. Finally, from the comparison table you create, conclude which model performed the best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (153721724.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_73/153721724.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    test_results_m1 <- ridge_fit %>% # calling out the data for the first model\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Fitting the models on the testing data:\n",
    "## A. Model 1:\n",
    "test_results_m1 <- ridge_fit %>% # calling out the data for the first model\n",
    "  predict(new_data = noaa_testing) %>% # predicting precipitation (dependent variable) in our model by using the testing data on explanatory variables\n",
    "  mutate(truth = noaa_testing$precip) # adding the corresponding actual precipitation to the table\n",
    "\n",
    "ridge_rmse_testing <- rmse(test_results_m1, truth = truth, estimate = .pred)[,3] %>% as.numeric()\n",
    "\n",
    "## B. Model 2:\n",
    "\n",
    "# First we need to fit the model based on the training data:\n",
    "\n",
    "# Defining the engine behind the model\n",
    "poly_spec <- linear_reg() %>% \n",
    "  set_engine(\"lm\")\n",
    "\n",
    "# Training the model\n",
    "poly_fit <- poly_spec %>%\n",
    "  fit(noaa_training$precip ~ poly(relative_humidity, degree = 2, raw = TRUE) +\n",
    "        poly(station_pressure, degree = 2, raw = TRUE)\n",
    "      , data = noaa_training)\n",
    "\n",
    "# Using the testing data on the trained model:\n",
    "test_results_m2 <- poly_fit %>%\n",
    "  predict(new_data = noaa_testing) %>%\n",
    "  mutate(truth = noaa_testing$precip)\n",
    "\n",
    "poly_rmse_testing <- rmse(test_results_m2, truth = truth, estimate = .pred)[,3] %>% as.numeric()\n",
    "\n",
    "# Comparing the two models by using a table (data frame):\n",
    "model_names <- c(\"Ridge\", \"Poly\")\n",
    "train_rmse <- c(ridge_rmse_training, poly_rmse_training)\n",
    "test_rmse <- c(ridge_rmse_testing, poly_rmse_testing)\n",
    "\n",
    "comparison_df <- data.frame(model_names, train_rmse, test_rmse)\n",
    "comparison_df\n",
    "\n",
    "# It is interesting that the training error, as measured by RMSE, was lower for the Ridge model,\n",
    "# fitting the testing data on the model would result in a lower RMSE for the poly model. \n",
    "# In this sense, although the Ridge model is better in explaining the variation of the data,\n",
    "# it seems like it is relatively over-fitted. To the degree that the predictable ability of the poly model is \n",
    "# higher than the ridge model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author(s)\n",
    "\n",
    "<h4> Yiwen Li </h4>\n",
    "\n",
    "## Contributions\n",
    "\n",
    "<h4> Tiffany Zhu </h4>\n",
    "\n",
    "## <h3 align=\"center\"> © IBM Corporation 2021. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
